{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3cd2c03-3bd4-46b7-972f-fc90f232b294",
   "metadata": {},
   "source": [
    "# compare MPS vs CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f92905ad-d970-405e-88ff-edb976f9105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede5fbbb-1498-4d8e-a65a-dc229781b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch \n",
    "import datasets\n",
    "import random\n",
    "\n",
    "# r50k_base vocab size: 50,257 https://arxiv.org/pdf/2404.09894\n",
    "enc = tiktoken.get_encoding(\"r50k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "def encode(string):\n",
    "    return torch.tensor(enc.encode(string))\n",
    "\n",
    "def decode(tensor):\n",
    "    return enc.decode([tensor.item()])\n",
    "    \n",
    "def get_sample(split, sample_length):\n",
    "    tokens = dataset_tok[split][\"tok\"][0]\n",
    "    s = random.randint(0, len(tokens)-sample_length)\n",
    "    return torch.tensor(tokens[s:s+sample_length], device=device), torch.tensor(tokens[s+sample_length], device=device)\n",
    "\n",
    "dataset = datasets.load_dataset('karpathy/tiny_shakespeare')\n",
    "dataset_tok = dataset.map(lambda row: {\"tok\": encode(row[\"text\"])}, remove_columns=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd570a38-8aa1-45a0-b4ba-43c573c0d3bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)): get_sample(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "# for i in tqdm(range(1000)): get_sample(\"train\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef07949c-ea5d-4c42-9d2c-6060f4940a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = out.mean(dim=0)  # Average the embeddings to get a single vector per sentence\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "    def generate(self, prompt, tokens):\n",
    "        with torch.no_grad():\n",
    "            for _ in range(tokens):\n",
    "                input_tok = encode(prompt).to(device)\n",
    "                output_tok = self(input_tok)\n",
    "                output = decode(torch.argmax(output_tok))\n",
    "                prompt = prompt + output\n",
    "            return prompt\n",
    "        \n",
    "model = MLP(vocab_size=50_272, embedding_dim=1024, hidden_size=512, num_classes=50_272)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae72246-6ae3-4b71-ba64-0a71e7d8a504",
   "metadata": {},
   "source": [
    "## cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3edbf53f-4f20-4ae4-8d72-b80e8a8a4c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20: loss 10.82 78.95ms 127tok/s (total 190 tok)\n",
      "step 40: loss 10.85 81.87ms 122tok/s (total 390 tok)\n",
      "step 60: loss 10.91 80.32ms 125tok/s (total 590 tok)\n",
      "step 80: loss 10.84 78.58ms 127tok/s (total 790 tok)\n",
      "step 100: loss 10.69 79.25ms 126tok/s (total 990 tok)\n",
      "Oh my lord Utahlav\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "step 120: loss 10.70 79.28ms 126tok/s (total 1,190 tok)\n",
      "step 140: loss 10.96 80.29ms 125tok/s (total 1,390 tok)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import time\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "curr_time = time.time()\n",
    "curr_step = 1\n",
    "curr_tok = 0\n",
    "\n",
    "for curr_step in range(1, 150):\n",
    "    inputs, labels = get_sample(\"train\", 10)\n",
    "    tok_cnt = inputs.size()[0]\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (curr_step % 20 == 0):\n",
    "        step_time = time.time() - curr_time\n",
    "        print(f\"step {curr_step}: loss {loss.detach().item():.2f} {step_time*1000:.2f}ms {(tok_cnt/step_time):.0f}tok/s (total {curr_tok:,} tok)\")\n",
    "\n",
    "    if (curr_step % 100 == 0):\n",
    "        print(model.generate(\"Oh my lord\", 10))\n",
    "    \n",
    "    curr_time = time.time() \n",
    "    curr_step = curr_step + 1\n",
    "    curr_tok = curr_tok + tok_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c7be9-8a93-4ef1-8586-1452db6f3eed",
   "metadata": {},
   "source": [
    "## MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4598433c-fcc6-4de7-a794-f6fdf477747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb30d1c6-c9d8-4f30-926e-10ef4f66e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20: loss 10.05 45.34ms 221tok/s (total 190 tok)\n",
      "step 40: loss 10.78 44.80ms 223tok/s (total 390 tok)\n",
      "step 60: loss 10.79 45.28ms 221tok/s (total 590 tok)\n",
      "step 80: loss 11.04 44.76ms 223tok/s (total 790 tok)\n",
      "step 100: loss 10.93 45.26ms 221tok/s (total 990 tok)\n",
      "Oh my lord\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "step 120: loss 4.64 44.26ms 226tok/s (total 1,190 tok)\n",
      "step 140: loss 10.83 47.11ms 212tok/s (total 1,390 tok)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import time\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "curr_time = time.time()\n",
    "curr_step = 1\n",
    "curr_tok = 0\n",
    "\n",
    "for curr_step in range(1, 150):\n",
    "    inputs, labels = get_sample(\"train\", 10)\n",
    "    tok_cnt = inputs.size()[0]\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (curr_step % 20 == 0):\n",
    "        step_time = time.time() - curr_time\n",
    "        print(f\"step {curr_step}: loss {loss.detach().item():.2f} {step_time*1000:.2f}ms {(tok_cnt/step_time):.0f}tok/s (total {curr_tok:,} tok)\")\n",
    "\n",
    "    if (curr_step % 100 == 0):\n",
    "        print(model.generate(\"Oh my lord\", 10))\n",
    "    \n",
    "    curr_time = time.time() \n",
    "    curr_step = curr_step + 1\n",
    "    curr_tok = curr_tok + tok_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61712214-39c9-43ae-91ae-d675a9829715",
   "metadata": {},
   "source": [
    "# more simple NN: embedding only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfaa5f3b-8ef3-4d88-bedc-230bc34efba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5caad78c-1551-4474-9716-de078985f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch \n",
    "import datasets\n",
    "import random\n",
    "\n",
    "# r50k_base vocab size: 50,257 https://arxiv.org/pdf/2404.09894\n",
    "enc = tiktoken.get_encoding(\"r50k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "def encode(string):\n",
    "    return torch.tensor(enc.encode(string))\n",
    "\n",
    "def decode(tensor):\n",
    "    return enc.decode([tensor.item()])\n",
    "    \n",
    "def get_sample(split, sample_length):\n",
    "    tokens = dataset_tok[split][\"tok\"][0]\n",
    "    s = random.randint(0, len(tokens)-sample_length)\n",
    "    return torch.tensor(tokens[s:s+sample_length], device=device), torch.tensor(tokens[s+sample_length], device=device)\n",
    "\n",
    "dataset = datasets.load_dataset('karpathy/tiny_shakespeare')\n",
    "dataset_tok = dataset.map(lambda row: {\"tok\": encode(row[\"text\"])}, remove_columns=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8355cb67-c669-4494-8d18-15db021b669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = out.mean(dim=0)  # Average the embeddings to get a single vector per sentence\n",
    "        return out\n",
    "\n",
    "    def generate(self, prompt, tokens):\n",
    "        with torch.no_grad():\n",
    "            for _ in range(tokens):\n",
    "                input_tok = encode(prompt).to(device)\n",
    "                output_tok = self(input_tok)\n",
    "                output = decode(torch.argmax(output_tok))\n",
    "                prompt = prompt + output\n",
    "            return prompt\n",
    "        \n",
    "model = MLP(vocab_size=50_272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2a8bbe-f988-442b-99a5-a4c0ba88fbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2527.273984M parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{count_parameters(model)/1_000_000}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d382a5-5721-468c-90c1-f4e07366c05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (embedding): Embedding(50272, 50272)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5630837-2fc6-4bfb-bff9-32d7a084c4bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 18.85 GB, other allocations: 9.42 GB, max allowed: 27.20 GB). Tried to allocate 256 bytes on shared pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 24\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (curr_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     27\u001b[0m     step_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m curr_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/sgd.py:80\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     76\u001b[0m momentum_buffer_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     78\u001b[0m has_sparse_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(group, params_with_grad, d_p_list, momentum_buffer_list)\n\u001b[0;32m---> 80\u001b[0m \u001b[43msgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdampening\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnesterov\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p, momentum_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/sgd.py:245\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, fused, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 245\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m     \u001b[49m\u001b[43md_p_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmomentum_buffer_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdampening\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdampening\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m     \u001b[49m\u001b[43mnesterov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnesterov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_sparse_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/sgd.py:293\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, grad_scale, found_inf, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m         d_p \u001b[38;5;241m=\u001b[39m buf\n\u001b[0;32m--> 293\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 18.85 GB, other allocations: 9.42 GB, max allowed: 27.20 GB). Tried to allocate 256 bytes on shared pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import time\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "curr_time = time.time()\n",
    "curr_step = 1\n",
    "curr_tok = 0\n",
    "\n",
    "for curr_step in range(1, 150):\n",
    "    inputs, labels = get_sample(\"train\", 10)\n",
    "    tok_cnt = inputs.size()[0]\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (curr_step % 20 == 0):\n",
    "        step_time = time.time() - curr_time\n",
    "        print(f\"step {curr_step}: loss {loss.detach().item():.2f} {step_time*1000:.2f}ms {(tok_cnt/step_time):.0f}tok/s (total {curr_tok:,} tok)\")\n",
    "\n",
    "    if (curr_step % 100 == 0):\n",
    "        print(model.generate(\"Oh my lord\", 10))\n",
    "    \n",
    "    curr_time = time.time() \n",
    "    curr_step = curr_step + 1\n",
    "    curr_tok = curr_tok + tok_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d40728-a1e0-4ffa-94be-3a96fb846553",
   "metadata": {},
   "source": [
    "# benchmark get_sample function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50324938-2d90-43fd-a3c8-4765b5c1d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch \n",
    "import datasets\n",
    "import random\n",
    "\n",
    "# r50k_base vocab size: 50,257 https://arxiv.org/pdf/2404.09894\n",
    "enc = tiktoken.get_encoding(\"r50k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "def encode(string):\n",
    "    return torch.tensor(enc.encode(string))\n",
    "\n",
    "def decode(tensor):\n",
    "    return enc.decode([tensor.item()])\n",
    "    \n",
    "dataset = datasets.load_dataset('karpathy/tiny_shakespeare')\n",
    "dataset_tok = dataset.map(lambda row: {\"tok\": encode(row[\"text\"])}, remove_columns=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6121301a-72d5-4357-85f0-a0f4a7ae8759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 200/200 [00:08<00:00, 24.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def get_sample(split, sample_length):\n",
    "    tokens = dataset_tok[split][\"tok\"][0]\n",
    "    s = random.randint(0, len(tokens)-sample_length)\n",
    "    return torch.tensor(tokens[s:s+sample_length]), torch.tensor(tokens[s+sample_length])\n",
    "\n",
    "for i in tqdm(range(200)): get_sample(\"train\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c42c5-1385-4558-a858-fca82e690094",
   "metadata": {},
   "source": [
    "## maybe creating a new tensor takes a lot of time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ab22f28-8e14-4457-884b-d5b67fb2c484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5029fa013ca643b789b5be00a7e2a692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fd/9xbk36z13vx8c3h6tbf6qchm0000gn/T/ipykernel_89023/715833380.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset_tok = dataset.map(lambda row: {\"tok\": torch.tensor(encode(row[\"text\"]))}, remove_columns=\"text\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79e7ed7412c4e6892665f027b94129c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2af27031fa4771a055ccd566a45d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch \n",
    "import datasets\n",
    "import random\n",
    "\n",
    "# r50k_base vocab size: 50,257 https://arxiv.org/pdf/2404.09894\n",
    "enc = tiktoken.get_encoding(\"r50k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "def encode(string):\n",
    "    return torch.tensor(enc.encode(string))\n",
    "\n",
    "def decode(tensor):\n",
    "    return enc.decode([tensor.item()])\n",
    "    \n",
    "dataset = datasets.load_dataset('karpathy/tiny_shakespeare')\n",
    "dataset_tok = dataset.map(lambda row: {\"tok\": torch.tensor(encode(row[\"text\"]))}, remove_columns=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0165a26b-e9f8-4a13-b82d-d38d9d68c761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 200/200 [00:07<00:00, 25.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def get_sample(split, sample_length):\n",
    "    tokens = dataset_tok[split][\"tok\"][0]\n",
    "    s = random.randint(0, len(tokens)-sample_length)\n",
    "    return tokens[s:s+sample_length], tokens[s+sample_length]\n",
    "\n",
    "for i in tqdm(range(200)): get_sample(\"train\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bc9b502-8d54-4b21-b496-4433a0647b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be04746678cd482295e7bb781de3774f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fd/9xbk36z13vx8c3h6tbf6qchm0000gn/T/ipykernel_89023/2329617462.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset_tok = dataset.map(lambda row: {\"tok\": torch.tensor(encode(row[\"text\"]), device=\"mps\")}, remove_columns=\"text\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad7435cd2d84043b35c0538a1b2e55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2701c6b244409fb7227ab32e90c1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch \n",
    "import datasets\n",
    "import random\n",
    "\n",
    "# r50k_base vocab size: 50,257 https://arxiv.org/pdf/2404.09894\n",
    "enc = tiktoken.get_encoding(\"r50k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "def encode(string):\n",
    "    return torch.tensor(enc.encode(string))\n",
    "\n",
    "def decode(tensor):\n",
    "    return enc.decode([tensor.item()])\n",
    "    \n",
    "dataset = datasets.load_dataset('karpathy/tiny_shakespeare')\n",
    "dataset_tok = dataset.map(lambda row: {\"tok\": torch.tensor(encode(row[\"text\"]), device=\"mps\")}, remove_columns=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb55c961-bcd5-49af-bb5d-cd71eacd34a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 200/200 [00:07<00:00, 25.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def get_sample(split, sample_length):\n",
    "    tokens = dataset_tok[split][\"tok\"][0]\n",
    "    s = random.randint(0, len(tokens)-sample_length)\n",
    "    return tokens[s:s+sample_length], tokens[s+sample_length]\n",
    "\n",
    "for i in tqdm(range(200)): get_sample(\"train\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5411d827-ab92-4f72-b991-a322b1ad163c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 200/200 [00:07<00:00, 25.61it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def get_sample(split, sample_length):\n",
    "    tokens = dataset_tok[split][\"tok\"][0]\n",
    "    s = 5\n",
    "    return tokens[s:s+sample_length], tokens[s+sample_length]\n",
    "\n",
    "for i in tqdm(range(200)): get_sample(\"train\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ead727bb-bbf5-4d0c-a365-656f449171a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 200/200 [00:07<00:00, 25.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def get_sample(split, sample_length):\n",
    "    tokens = dataset_tok[split][\"tok\"][0]\n",
    "    s = 5\n",
    "    return tokens[s:s+sample_length]\n",
    "\n",
    "for i in tqdm(range(200)): get_sample(\"train\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4d24462-1513-4b5e-b470-56c110edf954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 200/200 [00:07<00:00, 25.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def get_sample(split, sample_length):\n",
    "    tokens = dataset_tok[split][\"tok\"][0]\n",
    "    s = 5\n",
    "    return tokens\n",
    "\n",
    "for i in tqdm(range(200)): get_sample(\"train\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c71843b6-0729-4511-8015-b3ce8beef104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 49902.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def get_sample(split, sample_length):\n",
    "    # tokens = dataset_tok[split][\"tok\"][0]\n",
    "    s = 5\n",
    "    return s\n",
    "\n",
    "for i in tqdm(range(200)): get_sample(\"train\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b319e972-f9ee-4b25-84e8-9cb4caca5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = torch.tensor(dataset_tok[\"train\"][\"tok\"][0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1902fcdb-96cc-4b97-9266-9829776217b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b88c3a13-f32f-434d-bc6e-132fed165089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.long()\n",
    "tok.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1f3be58-af9c-45aa-8704-17fcae8d8010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 0],\n",
       "        [3, 4],\n",
       "        [4, 3],\n",
       "        [4, 2]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(5, (4,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e31b294-aaf7-4585-8c0a-fc377b6e442f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "randint(low=0, high, size, \\*, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
       "\n",
       "Returns a tensor filled with random integers generated uniformly\n",
       "between :attr:`low` (inclusive) and :attr:`high` (exclusive).\n",
       "\n",
       "The shape of the tensor is defined by the variable argument :attr:`size`.\n",
       "\n",
       ".. note::\n",
       "    With the global dtype default (``torch.float32``), this function returns\n",
       "    a tensor with dtype ``torch.int64``.\n",
       "\n",
       "Args:\n",
       "    low (int, optional): Lowest integer to be drawn from the distribution. Default: 0.\n",
       "    high (int): One above the highest integer to be drawn from the distribution.\n",
       "    size (tuple): a tuple defining the shape of the output tensor.\n",
       "\n",
       "Keyword args:\n",
       "    generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
       "    out (Tensor, optional): the output tensor.\n",
       "    dtype (`torch.dtype`, optional) - the desired data type of returned tensor. Default: if ``None``,\n",
       "        this function returns a tensor with dtype ``torch.int64``.\n",
       "    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
       "        Default: ``torch.strided``.\n",
       "    device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
       "        Default: if ``None``, uses the current device for the default tensor type\n",
       "        (see :func:`torch.set_default_device`). :attr:`device` will be the CPU\n",
       "        for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
       "    requires_grad (bool, optional): If autograd should record operations on the\n",
       "        returned tensor. Default: ``False``.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.randint(3, 5, (3,))\n",
       "    tensor([4, 3, 4])\n",
       "\n",
       "\n",
       "    >>> torch.randint(10, (2, 2))\n",
       "    tensor([[0, 2],\n",
       "            [5, 5]])\n",
       "\n",
       "\n",
       "    >>> torch.randint(3, 10, (2, 2))\n",
       "    tensor([[4, 5],\n",
       "            [6, 7]])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.randint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e442b1f-c382-4c07-92e6-075d7934db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "emb = nn.Embedding(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30887f98-45d6-40a5-91e5-43088a607e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([0, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c182c127-a17b-4335-8834-1beac80ce282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(10, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6213a95c-292e-4b7b-adb3-359b270c5174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4692, -0.6647, -0.0064,  0.4490, -1.2883,  1.1145,  0.1919, -0.7953,\n",
       "          2.2297, -1.0140],\n",
       "        [ 0.7702,  0.7249, -0.0917,  1.4448,  1.1533,  1.2294,  0.3328,  1.9844,\n",
       "         -1.0909, -0.6624],\n",
       "        [-0.5557,  0.6507,  0.6215, -1.9482,  0.0234, -0.1776,  1.6709, -1.6300,\n",
       "         -0.6850,  0.2105]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57e390b5-e314-43a1-8355-71223b935f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a34ee2ee-c188-4bfd-8c61-d34738de282b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4],\n",
       "        [6, 3]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(10, (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61778b82-21a2-4895-8547-4cb7383cde12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 10])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(torch.randint(10, (2,2))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a613d81c-e163-48fb-9e3a-914133d3f450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 6, 5, 9],\n",
       "        [3, 0, 1, 1],\n",
       "        [2, 4, 1, 4]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(10, (3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d99b8ed-e9eb-423a-b679-b7df58085da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 10])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(torch.randint(10, (3,4))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec6d286c-cb80-4e03-a1ad-960fb1a0c2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2a6cb3c-cff7-4c0a-83a0-30daebfae6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4692, -0.6647, -0.0064,  0.4490, -1.2883,  1.1145,  0.1919, -0.7953,\n",
       "          2.2297, -1.0140],\n",
       "        [-1.7927,  0.0889, -0.8772, -0.2689,  0.3096,  1.0809,  0.8955, -1.7298,\n",
       "         -0.5292, -0.2212],\n",
       "        [ 0.7702,  0.7249, -0.0917,  1.4448,  1.1533,  1.2294,  0.3328,  1.9844,\n",
       "         -1.0909, -0.6624],\n",
       "        [-0.5557,  0.6507,  0.6215, -1.9482,  0.0234, -0.1776,  1.6709, -1.6300,\n",
       "         -0.6850,  0.2105],\n",
       "        [-1.4775,  0.5935, -2.4034,  1.5521, -0.8200, -0.6712,  0.2298,  0.7088,\n",
       "          0.4819,  0.7531],\n",
       "        [ 0.6940,  0.2879, -0.4894,  1.2471,  0.3382,  0.8189, -0.1822,  0.7593,\n",
       "         -1.4281,  0.5939],\n",
       "        [-0.5219, -0.5266,  1.2750,  1.7248,  0.8310,  0.0730,  1.3571,  0.2483,\n",
       "          0.1648,  0.2519],\n",
       "        [ 1.0359, -0.2647, -0.0677,  0.4956,  1.1466, -0.2427,  0.3803, -0.0629,\n",
       "          0.2553, -0.6983],\n",
       "        [ 1.2476, -0.5968,  1.3025, -1.9699,  0.8386,  0.4369, -1.6739, -0.2482,\n",
       "         -0.9271,  1.1132],\n",
       "        [-1.0896,  0.3829, -1.1818, -0.0210,  1.0554,  2.2385, -0.2549,  0.0925,\n",
       "          1.0741,  1.5134]], requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e245343-312e-4041-b5a1-91386e502c1a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
