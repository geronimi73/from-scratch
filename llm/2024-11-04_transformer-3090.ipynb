{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bfe7b8f-e923-4722-ab8d-4665f052350d",
   "metadata": {},
   "source": [
    "* fineweb-edu\n",
    "* mfu calc\n",
    "* wandb logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e117625-0d57-4be1-8543-da491957c46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.18.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.24.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.26.0 (from tiktoken)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2023.4.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (3.11.0)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.6)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.17.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.4.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is still looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.4-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.24.1-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading huggingface_hub-0.24.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting fsspec[http]<=2024.9.0,>=2023.1.0 (from datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets)\n",
      "  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.18.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.17.0-py2.py3-none-any.whl (314 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.5/314.5 kB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, tqdm, smmap, setproctitle, sentry-sdk, requests, regex, pyarrow, protobuf, propcache, multidict, fsspec, frozenlist, docker-pycreds, dill, click, async-timeout, aiohappyeyeballs, yarl, tiktoken, pandas, multiprocess, huggingface-hub, gitdb, aiosignal, gitpython, aiohttp, wandb, datasets\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 async-timeout-4.0.3 click-8.1.7 datasets-3.1.0 dill-0.3.8 docker-pycreds-0.4.0 frozenlist-1.5.0 fsspec-2024.9.0 gitdb-4.0.11 gitpython-3.1.43 huggingface-hub-0.26.2 multidict-6.1.0 multiprocess-0.70.16 pandas-2.2.3 propcache-0.2.0 protobuf-5.28.3 pyarrow-18.0.0 pytz-2024.2 regex-2024.9.11 requests-2.32.3 sentry-sdk-2.17.0 setproctitle-1.3.3 smmap-5.0.1 tiktoken-0.8.0 tqdm-4.66.6 tzdata-2024.2 wandb-0.18.5 xxhash-3.5.0 yarl-1.17.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken tqdm datasets wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b100d83e-dba3-43fd-9386-1fc1d9eacf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random, numpy as np\n",
    "\n",
    "vocab_size = 50_272\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "batch_size = 64\n",
    "block_size = 128 \n",
    "learning_rate = 3e-4\n",
    "\n",
    "# seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# GPUs\n",
    "gpus = {\n",
    "    \"M3\": [4.1 * 10**12, \"mps\"],\n",
    "    \"4090\": [82 * 10**12, \"cuda\"],\n",
    "    \"3090\": [35.58 * 10**12, \"cuda\"],\n",
    "}\n",
    "gpu = \"3090\"\n",
    "flops_promised, device = gpus[gpu]\n",
    "\n",
    "# device = \"mps\"\n",
    "# flops_promised = 4.1 * 10**12 if device == \"mps\" else 82 * 10**12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7d9c4a-630c-40e0-94e4-86cbc08c0581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0728a1d628e946da8a38592c6c266523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/23.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7666a74df1db4d55a1f1b7d07c408c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "000_00000.parquet:   0%|          | 0.00/2.15G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f989f8e91744b2d8819d6d8ce3b7469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:10<00:00, 1409.30it/s]\n",
      "100%|██████████| 100000/100000 [01:07<00:00, 1479.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "import torch \n",
    "import datasets\n",
    "import random\n",
    "\n",
    "dataset = datasets.load_dataset(\"HuggingFaceFW/fineweb-edu\", data_files=[\"sample/10BT/000_00000.parquet\"], split=\"train\")\n",
    "dataset = dataset.train_test_split()\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "def encode(string):\n",
    "    return torch.tensor(enc.encode(string), dtype=torch.long)\n",
    "\n",
    "def decode(tensor):\n",
    "    return enc.decode(tensor.cpu().squeeze().numpy())\n",
    "\n",
    "num_samples = 100_000\n",
    "dataset_tok_train = torch.cat([encode(dataset[\"train\"][i][\"text\"]) for i in tqdm(range(num_samples))])\n",
    "dataset_tok_test = torch.cat([encode(dataset[\"test\"][i][\"text\"]) for i in tqdm(range(num_samples))])\n",
    "\n",
    "def get_sample(split, sample_length, batch_size):\n",
    "    tokens = dataset_tok_train if split == \"train\" else dataset_tok_test\n",
    "    idcs = torch.randint(len(tokens)-sample_length, (batch_size,))\n",
    "    x = torch.stack([torch.tensor(tokens[x:x+sample_length]) for x in idcs])\n",
    "    y = torch.stack([torch.tensor(tokens[x+1:x+sample_length+1]) for x in idcs])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "869a87db-8bba-4726-aaea-0ce5603f8551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 105,042,560 tokens\n",
      "Test data: 104,150,265 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data: {len(dataset_tok_train):,} tokens\")\n",
    "print(f\"Test data: {len(dataset_tok_test):,} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d5a8b7d-7ece-41bc-89fe-443d5f5d1ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        # out = F.scaled_dot_product_attention(q, k, v)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "    def calculate_mfu(self, dt):\n",
    "        flops_achieved = flops_per_fwdbwd / dt\n",
    "        mfu = flops_achieved / flops_promised\n",
    "        # print(f\"{flops_achieved/10**12} TFLOPS achieved, {mfu * 100:.2f}% MFU\")\n",
    "        return mfu      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4112aec8-187a-445e-9cbb-dc953c0afc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.35M parameter model on devicecuda with 35.58 TFLOPS promised \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20241104_061321-dwhmtyw8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gerald-stampfel/minimal-llm/runs/dwhmtyw8' target=\"_blank\">GPT2-49.3M-BS-64-105.0MT-3090</a></strong> to <a href='https://wandb.ai/gerald-stampfel/minimal-llm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gerald-stampfel/minimal-llm' target=\"_blank\">https://wandb.ai/gerald-stampfel/minimal-llm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gerald-stampfel/minimal-llm/runs/dwhmtyw8' target=\"_blank\">https://wandb.ai/gerald-stampfel/minimal-llm/runs/dwhmtyw8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m No relevant files were detected in the specified directory. No code will be logged to your run.\n"
     ]
    }
   ],
   "source": [
    "model = GPTLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "num_params = sum(p.numel() for p in m.parameters())/1e6\n",
    "print(f\"{num_params:.2f}M parameter model on device{device} with {flops_promised / 10**12:,} TFLOPS promised \" )\n",
    "\n",
    "import wandb \n",
    "wandb.init(\n",
    "    project=\"minimal-llm\",\n",
    "    name=f\"GPT2-{num_params:.1f}M-BS-{batch_size}-{len(dataset_tok_train)/10**6:,.1f}MT-{gpu}\"\n",
    ").log_code(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28b8522f-1db1-43ad-8aa6-55a0103ce704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_401/1485170168.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.stack([torch.tensor(tokens[x:x+sample_length]) for x in idcs])\n",
      "/tmp/ipykernel_401/1485170168.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.stack([torch.tensor(tokens[x+1:x+sample_length+1]) for x in idcs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,499,681,783,808 flops per fwd+bwd pass\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "\n",
    "def get_flops(f):\n",
    "    flop_counter = FlopCounterMode(display=False)\n",
    "    with flop_counter:\n",
    "        f()\n",
    "    return flop_counter.get_total_flops() \n",
    "\n",
    "def train_one_sample():\n",
    "    xb, yb = get_sample('train', block_size, batch_size)\n",
    "    logits, loss = model(xb.to(device), yb.to(device))\n",
    "    loss.backward()\n",
    "\n",
    "flops_per_fwdbwd = get_flops(train_one_sample)\n",
    "print(f\"{flops_per_fwdbwd:,} flops per fwd+bwd pass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b09d994-9d8f-4a2a-8fa6-c2cf0fcb04ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_401/1485170168.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.stack([torch.tensor(tokens[x:x+sample_length]) for x in idcs])\n",
      "/tmp/ipykernel_401/1485170168.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.stack([torch.tensor(tokens[x+1:x+sample_length+1]) for x in idcs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10: loss 9.47 120.96ms/step 67,723tok/s (total 81,920 tok), 34.85% MFU\n",
      "step 20: loss 8.56 120.60ms/step 67,929tok/s (total 163,840 tok), 34.95% MFU\n",
      "step 30: loss 8.06 132.23ms/step 61,954tok/s (total 245,760 tok), 31.88% MFU\n",
      "step 40: loss 7.68 132.68ms/step 61,743tok/s (total 327,680 tok), 31.77% MFU\n",
      "step 50: loss 7.69 132.99ms/step 61,600tok/s (total 409,600 tok), 31.69% MFU\n",
      "step 50 eval: val_loss 7.63\n",
      "step 60: loss 7.62 132.86ms/step 61,658tok/s (total 491,520 tok), 31.72% MFU\n",
      "step 70: loss 7.58 132.94ms/step 61,623tok/s (total 573,440 tok), 31.71% MFU\n",
      "step 80: loss 7.47 132.55ms/step 61,805tok/s (total 655,360 tok), 31.80% MFU\n",
      "step 90: loss 7.50 133.82ms/step 61,215tok/s (total 737,280 tok), 31.50% MFU\n",
      "step 100: loss 7.36 133.19ms/step 61,506tok/s (total 819,200 tok), 31.65% MFU\n",
      "step 100 eval: val_loss 7.34\n",
      "step 110: loss 7.17 133.75ms/step 61,249tok/s (total 901,120 tok), 31.51% MFU\n",
      "step 120: loss 7.11 132.09ms/step 62,021tok/s (total 983,040 tok), 31.91% MFU\n",
      "step 130: loss 6.97 133.68ms/step 61,282tok/s (total 1,064,960 tok), 31.53% MFU\n",
      "step 140: loss 7.11 133.52ms/step 61,356tok/s (total 1,146,880 tok), 31.57% MFU\n",
      "step 150: loss 6.92 122.19ms/step 67,042tok/s (total 1,228,800 tok), 34.49% MFU\n",
      "step 150 eval: val_loss 7.02\n",
      "step 160: loss 7.05 125.43ms/step 65,313tok/s (total 1,310,720 tok), 33.60% MFU\n",
      "step 170: loss 7.00 133.96ms/step 61,151tok/s (total 1,392,640 tok), 31.46% MFU\n",
      "step 180: loss 6.97 132.72ms/step 61,726tok/s (total 1,474,560 tok), 31.76% MFU\n",
      "step 190: loss 6.79 132.92ms/step 61,630tok/s (total 1,556,480 tok), 31.71% MFU\n",
      "step 200: loss 6.92 133.20ms/step 61,500tok/s (total 1,638,400 tok), 31.64% MFU\n",
      "step 200 eval: val_loss 6.77\n",
      "step 210: loss 6.76 133.04ms/step 61,577tok/s (total 1,720,320 tok), 31.68% MFU\n",
      "step 220: loss 6.70 133.99ms/step 61,138tok/s (total 1,802,240 tok), 31.46% MFU\n",
      "step 230: loss 6.64 135.08ms/step 60,648tok/s (total 1,884,160 tok), 31.20% MFU\n",
      "step 240: loss 6.62 123.55ms/step 66,307tok/s (total 1,966,080 tok), 34.12% MFU\n",
      "step 250: loss 6.72 132.94ms/step 61,624tok/s (total 2,048,000 tok), 31.71% MFU\n",
      "step 250 eval: val_loss 6.62\n",
      "step 260: loss 6.63 133.06ms/step 61,568tok/s (total 2,129,920 tok), 31.68% MFU\n",
      "step 270: loss 6.69 132.35ms/step 61,897tok/s (total 2,211,840 tok), 31.85% MFU\n",
      "step 280: loss 6.62 131.39ms/step 62,348tok/s (total 2,293,760 tok), 32.08% MFU\n",
      "step 290: loss 6.75 132.83ms/step 61,671tok/s (total 2,375,680 tok), 31.73% MFU\n",
      "step 300: loss 6.70 130.90ms/step 62,581tok/s (total 2,457,600 tok), 32.20% MFU\n",
      "step 300 eval: val_loss 6.62\n",
      "step 310: loss 6.60 130.39ms/step 62,828tok/s (total 2,539,520 tok), 32.33% MFU\n",
      "step 320: loss 6.59 130.70ms/step 62,678tok/s (total 2,621,440 tok), 32.25% MFU\n",
      "step 330: loss 6.53 132.56ms/step 61,801tok/s (total 2,703,360 tok), 31.80% MFU\n",
      "step 340: loss 6.58 132.49ms/step 61,832tok/s (total 2,785,280 tok), 31.81% MFU\n",
      "step 350: loss 6.47 129.17ms/step 63,418tok/s (total 2,867,200 tok), 32.63% MFU\n",
      "step 350 eval: val_loss 6.41\n",
      "step 360: loss 6.41 132.03ms/step 62,049tok/s (total 2,949,120 tok), 31.93% MFU\n",
      "step 370: loss 6.57 132.54ms/step 61,807tok/s (total 3,031,040 tok), 31.80% MFU\n",
      "step 380: loss 6.34 126.00ms/step 65,017tok/s (total 3,112,960 tok), 33.45% MFU\n",
      "step 390: loss 6.44 132.14ms/step 61,997tok/s (total 3,194,880 tok), 31.90% MFU\n",
      "step 400: loss 6.39 132.17ms/step 61,983tok/s (total 3,276,800 tok), 31.89% MFU\n",
      "step 400 eval: val_loss 6.35\n",
      "step 410: loss 6.51 133.57ms/step 61,332tok/s (total 3,358,720 tok), 31.56% MFU\n",
      "step 420: loss 6.44 132.17ms/step 61,982tok/s (total 3,440,640 tok), 31.89% MFU\n",
      "step 430: loss 6.45 132.40ms/step 61,873tok/s (total 3,522,560 tok), 31.84% MFU\n",
      "step 440: loss 6.29 132.42ms/step 61,863tok/s (total 3,604,480 tok), 31.83% MFU\n",
      "step 450: loss 6.30 133.01ms/step 61,588tok/s (total 3,686,400 tok), 31.69% MFU\n",
      "step 450 eval: val_loss 6.37\n",
      "step 460: loss 6.40 133.24ms/step 61,484tok/s (total 3,768,320 tok), 31.63% MFU\n",
      "step 470: loss 6.35 132.76ms/step 61,704tok/s (total 3,850,240 tok), 31.75% MFU\n",
      "step 480: loss 6.42 132.00ms/step 62,060tok/s (total 3,932,160 tok), 31.93% MFU\n",
      "step 490: loss 6.32 132.19ms/step 61,970tok/s (total 4,014,080 tok), 31.88% MFU\n",
      "step 500: loss 6.24 124.15ms/step 65,984tok/s (total 4,096,000 tok), 33.95% MFU\n",
      "step 500 eval: val_loss 6.36\n",
      "step 510: loss 6.31 133.41ms/step 61,404tok/s (total 4,177,920 tok), 31.59% MFU\n",
      "step 520: loss 6.39 132.70ms/step 61,734tok/s (total 4,259,840 tok), 31.76% MFU\n",
      "step 530: loss 6.18 131.92ms/step 62,100tok/s (total 4,341,760 tok), 31.95% MFU\n",
      "step 540: loss 6.23 132.62ms/step 61,769tok/s (total 4,423,680 tok), 31.78% MFU\n",
      "step 550: loss 6.32 133.23ms/step 61,485tok/s (total 4,505,600 tok), 31.64% MFU\n",
      "step 550 eval: val_loss 6.26\n",
      "step 560: loss 6.26 133.47ms/step 61,377tok/s (total 4,587,520 tok), 31.58% MFU\n",
      "step 570: loss 6.25 131.61ms/step 62,244tok/s (total 4,669,440 tok), 32.03% MFU\n",
      "step 580: loss 6.29 133.86ms/step 61,200tok/s (total 4,751,360 tok), 31.49% MFU\n",
      "step 590: loss 6.31 134.12ms/step 61,077tok/s (total 4,833,280 tok), 31.43% MFU\n",
      "step 600: loss 6.20 128.82ms/step 63,592tok/s (total 4,915,200 tok), 32.72% MFU\n",
      "step 600 eval: val_loss 6.22\n",
      "step 610: loss 6.34 132.77ms/step 61,703tok/s (total 4,997,120 tok), 31.75% MFU\n",
      "step 620: loss 6.17 125.12ms/step 65,473tok/s (total 5,079,040 tok), 33.69% MFU\n",
      "step 630: loss 6.08 133.47ms/step 61,377tok/s (total 5,160,960 tok), 31.58% MFU\n",
      "step 640: loss 6.21 132.14ms/step 61,996tok/s (total 5,242,880 tok), 31.90% MFU\n",
      "step 650: loss 6.22 133.21ms/step 61,497tok/s (total 5,324,800 tok), 31.64% MFU\n",
      "step 650 eval: val_loss 6.12\n",
      "step 660: loss 6.27 127.78ms/step 64,111tok/s (total 5,406,720 tok), 32.99% MFU\n",
      "step 670: loss 6.21 132.44ms/step 61,855tok/s (total 5,488,640 tok), 31.83% MFU\n",
      "step 680: loss 6.18 132.89ms/step 61,646tok/s (total 5,570,560 tok), 31.72% MFU\n",
      "step 690: loss 5.99 134.04ms/step 61,115tok/s (total 5,652,480 tok), 31.44% MFU\n",
      "step 700: loss 6.14 132.43ms/step 61,857tok/s (total 5,734,400 tok), 31.83% MFU\n",
      "step 700 eval: val_loss 6.13\n",
      "step 710: loss 6.03 132.74ms/step 61,715tok/s (total 5,816,320 tok), 31.75% MFU\n",
      "step 720: loss 6.08 133.18ms/step 61,511tok/s (total 5,898,240 tok), 31.65% MFU\n",
      "step 730: loss 6.05 133.21ms/step 61,495tok/s (total 5,980,160 tok), 31.64% MFU\n",
      "step 740: loss 6.08 131.54ms/step 62,278tok/s (total 6,062,080 tok), 32.04% MFU\n",
      "step 750: loss 5.93 133.19ms/step 61,508tok/s (total 6,144,000 tok), 31.65% MFU\n",
      "step 750 eval: val_loss 6.06\n",
      "step 760: loss 6.15 132.56ms/step 61,799tok/s (total 6,225,920 tok), 31.80% MFU\n",
      "step 770: loss 6.18 132.35ms/step 61,898tok/s (total 6,307,840 tok), 31.85% MFU\n",
      "step 780: loss 6.07 133.15ms/step 61,526tok/s (total 6,389,760 tok), 31.66% MFU\n",
      "step 790: loss 6.04 133.61ms/step 61,312tok/s (total 6,471,680 tok), 31.55% MFU\n",
      "step 800: loss 5.97 133.08ms/step 61,557tok/s (total 6,553,600 tok), 31.67% MFU\n",
      "step 800 eval: val_loss 5.86\n",
      "step 810: loss 6.12 133.77ms/step 61,241tok/s (total 6,635,520 tok), 31.51% MFU\n",
      "step 820: loss 5.97 124.23ms/step 65,944tok/s (total 6,717,440 tok), 33.93% MFU\n",
      "step 830: loss 5.94 124.70ms/step 65,695tok/s (total 6,799,360 tok), 33.80% MFU\n",
      "step 840: loss 6.03 133.54ms/step 61,343tok/s (total 6,881,280 tok), 31.56% MFU\n",
      "step 850: loss 5.99 128.24ms/step 63,882tok/s (total 6,963,200 tok), 32.87% MFU\n",
      "step 850 eval: val_loss 5.90\n",
      "step 860: loss 6.10 131.37ms/step 62,356tok/s (total 7,045,120 tok), 32.08% MFU\n",
      "step 870: loss 5.95 131.84ms/step 62,135tok/s (total 7,127,040 tok), 31.97% MFU\n",
      "step 880: loss 5.95 132.14ms/step 61,997tok/s (total 7,208,960 tok), 31.90% MFU\n",
      "step 890: loss 5.97 129.09ms/step 63,461tok/s (total 7,290,880 tok), 32.65% MFU\n",
      "step 900: loss 5.98 129.98ms/step 63,025tok/s (total 7,372,800 tok), 32.43% MFU\n",
      "step 900 eval: val_loss 5.96\n",
      "step 910: loss 5.92 125.06ms/step 65,504tok/s (total 7,454,720 tok), 33.70% MFU\n",
      "step 920: loss 5.92 127.93ms/step 64,036tok/s (total 7,536,640 tok), 32.95% MFU\n",
      "step 930: loss 5.98 123.94ms/step 66,099tok/s (total 7,618,560 tok), 34.01% MFU\n",
      "step 940: loss 5.91 135.58ms/step 60,421tok/s (total 7,700,480 tok), 31.09% MFU\n",
      "step 950: loss 5.91 134.76ms/step 60,790tok/s (total 7,782,400 tok), 31.28% MFU\n",
      "step 950 eval: val_loss 5.86\n",
      "step 960: loss 5.90 134.71ms/step 60,810tok/s (total 7,864,320 tok), 31.29% MFU\n",
      "step 970: loss 5.94 134.45ms/step 60,931tok/s (total 7,946,240 tok), 31.35% MFU\n",
      "step 980: loss 5.78 124.24ms/step 65,938tok/s (total 8,028,160 tok), 33.93% MFU\n",
      "step 990: loss 5.83 136.58ms/step 59,979tok/s (total 8,110,080 tok), 30.86% MFU\n",
      "step 1000: loss 5.85 134.63ms/step 60,846tok/s (total 8,192,000 tok), 31.31% MFU\n",
      "step 1000 eval: val_loss 5.82\n",
      "step 1010: loss 6.00 134.48ms/step 60,915tok/s (total 8,273,920 tok), 31.34% MFU\n",
      "step 1020: loss 5.84 133.99ms/step 61,137tok/s (total 8,355,840 tok), 31.46% MFU\n",
      "step 1030: loss 5.89 134.76ms/step 60,789tok/s (total 8,437,760 tok), 31.28% MFU\n",
      "step 1040: loss 5.85 134.48ms/step 60,917tok/s (total 8,519,680 tok), 31.34% MFU\n",
      "step 1050: loss 5.94 134.14ms/step 61,070tok/s (total 8,601,600 tok), 31.42% MFU\n",
      "step 1050 eval: val_loss 5.73\n",
      "step 1060: loss 5.82 134.18ms/step 61,052tok/s (total 8,683,520 tok), 31.41% MFU\n",
      "step 1070: loss 5.75 134.42ms/step 60,941tok/s (total 8,765,440 tok), 31.36% MFU\n",
      "step 1080: loss 5.95 134.81ms/step 60,768tok/s (total 8,847,360 tok), 31.27% MFU\n",
      "step 1090: loss 5.89 134.57ms/step 60,875tok/s (total 8,929,280 tok), 31.32% MFU\n",
      "step 1100: loss 5.72 138.21ms/step 59,274tok/s (total 9,011,200 tok), 30.50% MFU\n",
      "step 1100 eval: val_loss 5.73\n",
      "step 1110: loss 5.76 132.38ms/step 61,883tok/s (total 9,093,120 tok), 31.84% MFU\n",
      "step 1120: loss 5.72 124.41ms/step 65,849tok/s (total 9,175,040 tok), 33.88% MFU\n",
      "step 1130: loss 5.89 134.73ms/step 60,804tok/s (total 9,256,960 tok), 31.29% MFU\n",
      "step 1140: loss 5.81 135.95ms/step 60,258tok/s (total 9,338,880 tok), 31.00% MFU\n",
      "step 1150: loss 5.75 127.34ms/step 64,334tok/s (total 9,420,800 tok), 33.10% MFU\n",
      "step 1150 eval: val_loss 5.67\n",
      "step 1160: loss 5.86 128.60ms/step 63,700tok/s (total 9,502,720 tok), 32.77% MFU\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "log_interval = 10\n",
    "eval_interval = 50\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "curr_time = time.time()\n",
    "tok_total = 0 \n",
    "\n",
    "for curr_step in range(1, 1_000_000):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_sample('train', block_size, batch_size)\n",
    "    tok_step = xb.view(-1).size(0)\n",
    "    tok_total += tok_step\n",
    "\n",
    "    # evaluate the loss\n",
    "    step_start = time.time()\n",
    "    logits, loss = model(xb.to(device), yb.to(device))\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    step_time = time.time() - step_start\n",
    "    \n",
    "    if curr_step % log_interval == 0:\n",
    "        mfu = model.calculate_mfu(step_time)\n",
    "        print(f\"step {curr_step}: loss {loss.detach().item():.2f} {step_time*1000:.2f}ms/step {(tok_step/step_time):,.0f}tok/s (total {tok_total:,} tok), {mfu * 100:.2f}% MFU\")\n",
    "        wandb.log({\n",
    "            \"step\": curr_step,\n",
    "            \"tokens\": tok_total,\n",
    "            \"loss_train\": loss.detach().item(), \n",
    "            \"mfu\": mfu * 100, \n",
    "            \"tokens/s\": tok_step/step_time\n",
    "        })\n",
    "\n",
    "        \n",
    "    if curr_step % eval_interval == 0:\n",
    "        model.eval()\n",
    "        xb, yb = get_sample('validation', block_size, batch_size)\n",
    "        logits, loss = model(xb.to(device), yb.to(device))\n",
    "        print(f\"step {curr_step} eval: val_loss {loss.detach().item():.2f}\")\n",
    "        wandb.log({\n",
    "            \"step\": curr_step,\n",
    "            \"tokens\": tok_total,\n",
    "            \"loss_val\": loss.detach().item()\n",
    "        })\n",
    "        # with torch.no_grad():\n",
    "        #     output = model.generate(encode(\"hello my name is\").to(device).unsqueeze(0), 10)\n",
    "        #     print(decode(output))\n",
    "        model.train()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b477c-97b4-48b4-834d-6f334ea078a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model.generate(encode(\"Blue is\").to(device).unsqueeze(0), 50)\n",
    "    print(decode(output))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
