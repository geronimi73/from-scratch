{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b656c720-474c-4843-98be-51a17f86d322",
   "metadata": {},
   "source": [
    "# batched data loader with torch.stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a52af0c-4c9d-4e52-a9e7-d4a5cbbab6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch \n",
    "import datasets\n",
    "import random\n",
    "\n",
    "# r50k_base vocab size: 50,257 https://arxiv.org/pdf/2404.09894\n",
    "enc = tiktoken.get_encoding(\"r50k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "def encode(string):\n",
    "    return torch.tensor(enc.encode(string))\n",
    "\n",
    "def decode(tensor):\n",
    "    return enc.decode([tensor.item()])\n",
    "    \n",
    "dataset = datasets.load_dataset('karpathy/tiny_shakespeare')\n",
    "dataset_tok = dataset.map(lambda row: {\"tok\": torch.tensor(encode(row[\"text\"]), device=\"mps\")}, remove_columns=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c274d9e-62cb-49b1-962c-5b6805c33d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def get_sample(split, sample_length):\n",
    "    tokens = dataset_tok[split][\"tok\"][0]\n",
    "    s = random.randint(0, len(tokens)-sample_length)\n",
    "    return tokens[s:s+sample_length], tokens[s+sample_length]\n",
    "\n",
    "for i in tqdm(range(200)): get_sample(\"train\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "667b3dfe-0eeb-401f-83ff-a56ebdd56aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c8f70e8-75df-46e9-86a3-5dc34ca65b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=torch.tensor(dataset_tok[\"train\"][\"tok\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29de2f62-dfb6-4d44-a08e-8cb34a640862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5962)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2c58a97-e5ad-421c-b42e-83cff07fbbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([22307,    25,   198,  8421,   356,  5120,   597,  2252,    11,  3285]),\n",
       " tensor([  25,  198, 8421,  356, 5120,  597, 2252,   11, 3285,  502]),\n",
       " tensor([ 198, 8421,  356, 5120,  597, 2252,   11, 3285,  502, 2740]),\n",
       " tensor([8421,  356, 5120,  597, 2252,   11, 3285,  502, 2740,   13]),\n",
       " tensor([ 356, 5120,  597, 2252,   11, 3285,  502, 2740,   13,  198]),\n",
       " tensor([5120,  597, 2252,   11, 3285,  502, 2740,   13,  198,  198]),\n",
       " tensor([ 597, 2252,   11, 3285,  502, 2740,   13,  198,  198, 3237]),\n",
       " tensor([2252,   11, 3285,  502, 2740,   13,  198,  198, 3237,   25]),\n",
       " tensor([  11, 3285,  502, 2740,   13,  198,  198, 3237,   25,  198])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=10\n",
    "lst=[tokens[x:x+10] for x in range(1,bs)]\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b47c9638-ce9c-450a-a479-74853d2723e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22307,    25,   198,  8421,   356,  5120,   597,  2252,    11,  3285],\n",
       "        [   25,   198,  8421,   356,  5120,   597,  2252,    11,  3285,   502],\n",
       "        [  198,  8421,   356,  5120,   597,  2252,    11,  3285,   502,  2740],\n",
       "        [ 8421,   356,  5120,   597,  2252,    11,  3285,   502,  2740,    13],\n",
       "        [  356,  5120,   597,  2252,    11,  3285,   502,  2740,    13,   198],\n",
       "        [ 5120,   597,  2252,    11,  3285,   502,  2740,    13,   198,   198],\n",
       "        [  597,  2252,    11,  3285,   502,  2740,    13,   198,   198,  3237],\n",
       "        [ 2252,    11,  3285,   502,  2740,    13,   198,   198,  3237,    25],\n",
       "        [   11,  3285,   502,  2740,    13,   198,   198,  3237,    25,   198]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6553142f-10f7-4a8c-a3d1-df53e45ab8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(lst).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "497015eb-53fd-49a2-83da-89212b696387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22307,    25,   198,  8421,   356,  5120,   597,  2252,    11,  3285,\n",
       "           25,   198,  8421,   356,  5120,   597,  2252,    11,  3285,   502,\n",
       "          198,  8421,   356,  5120,   597,  2252,    11,  3285,   502,  2740,\n",
       "         8421,   356,  5120,   597,  2252,    11,  3285,   502,  2740,    13,\n",
       "          356,  5120,   597,  2252,    11,  3285,   502,  2740,    13,   198,\n",
       "         5120,   597,  2252,    11,  3285,   502,  2740,    13,   198,   198,\n",
       "          597,  2252,    11,  3285,   502,  2740,    13,   198,   198,  3237,\n",
       "         2252,    11,  3285,   502,  2740,    13,   198,   198,  3237,    25,\n",
       "           11,  3285,   502,  2740,    13,   198,   198,  3237,    25,   198])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "638b8b55-cdf2-434d-996b-3c2ea7b83c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(lst).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d85c72-530e-4aa2-a5b8-084cb8fb708b",
   "metadata": {},
   "source": [
    "## final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19560ce6-941a-431d-a7dc-ba4f3a3e542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken, torch, datasets, random\n",
    "\n",
    "# r50k_base vocab size: 50,257 https://arxiv.org/pdf/2404.09894\n",
    "enc = tiktoken.get_encoding(\"r50k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "def encode(string):\n",
    "    return torch.tensor(enc.encode(string))\n",
    "\n",
    "def decode(tensor):\n",
    "    return enc.decode([tensor.item()])\n",
    "    \n",
    "dataset = datasets.load_dataset('karpathy/tiny_shakespeare')\n",
    "dataset_tok = dataset.map(lambda row: {\"tok\": encode(row[\"text\"])}, remove_columns=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "649505e0-ed22-43d4-89f3-003be19210cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(split, sample_length, batch_size):\n",
    "    tokens = dataset_tok[split][\"tok\"][0]\n",
    "    idcs = torch.randint(len(tokens)-sample_length, (batch_size,))\n",
    "    x = torch.stack([torch.tensor(tokens[x:x+sample_length]) for x in idcs])\n",
    "    y = torch.stack([torch.tensor(tokens[x+1:x+sample_length+1]) for x in idcs])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8f57d0a1-a2be-46cc-875f-bf3d8ecd9d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   13,   198,   198],\n",
       "         [ 3073,   503,   286],\n",
       "         [   40,  1276, 22389],\n",
       "         [  750, 12201,   502],\n",
       "         [   81, 13055,   511],\n",
       "         [  198,  1870,   407],\n",
       "         [  952,   318,   339],\n",
       "         [ 8643,  1340,  9399],\n",
       "         [30158,  3525,  9399],\n",
       "         [ 1139,    11,   393]]),\n",
       " tensor([[  198,   198,    38],\n",
       "         [  503,   286,   262],\n",
       "         [ 1276, 22389,    25],\n",
       "         [12201,   502,    13],\n",
       "         [13055,   511, 15626],\n",
       "         [ 1870,   407,  9642],\n",
       "         [  318,   339,   668],\n",
       "         [ 1340,  9399,    25],\n",
       "         [ 3525,  9399,    25],\n",
       "         [   11,   393,   356]]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample(\"test\", 3, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
